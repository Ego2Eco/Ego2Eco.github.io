<!DOCTYPE html>
<html>
  <head>
    <title>AEE-GAN</title>
    <meta charset="utf-8">
  </head>
  <body>
    <center>
    <h1>Attended Ecology Embedding Generative Adversarial Network</h1>
    <h1>Implementation details</h1>
    <p align="center"><font size="5">
For Feature Encoder, we extract the visual features by fully convolutional networks and derive the feature maps with 512 channels, while the observed trajectories are encoded by a fully-connected layer with the embedding size of 5*64, fed into an LSTM with a dimension of 64 for the hidden state. The social features are embedded through a fully-connected layer with the embedding size 64. For Enforced Attention, the self-attention visual features are encoded by a 3*3 convolutional layer and one fully-connected layer with the dimension of 64. c' is set as c/8 due to the memory efficiency. Horizon Attention considers the road-agents in the horizon range within 10 meters, i.e., d=10. The decoder of generator uses LSTM with the hidden state of 64 dimensions to decode the predictions, while the discriminator uses two LSTM encoders with the hidden size of 64 dimensions to separately encode predicted trajectories and the observed path, and are further processed through two fully-connected layers with a size of 64 and 32. Finally, these outputs are concatenated and fed in two separate blocks: Trajectory Classifier and Latent Code Decoder which are consists of two fully-connected layers with respective size of (32,1) and (32,2). The proposed AEE-GAN is trained for 20000 epochs by Adam optimizer with a mini-batch size of 256. The learning rates for the generator and the discriminator are both 0.0001, and spectral normalization is used for layers in both generator and the discriminator.</font></p>
      <figure><img src="https://raw.githubusercontent.com/Ego2Eco/Ego2Eco.github.io/master/images/waymo.png" /></figure>
    <h1>Qualitative Results</h1>
    <figure><img src="https://raw.githubusercontent.com/Ego2Eco/Ego2Eco.github.io/master/images/visual.png" /></figure>
      <figure><img src="https://raw.githubusercontent.com/Ego2Eco/Ego2Eco.github.io/master/images/horizon.png" /></figure><font size="5">
      In the first scenario, figure (a) visualizes the attention weights of the Social Enforcement module, and figure (b) shows the prediction trajectories. S-WAYS fails to emphasize on the road-agents in front of the predicted agent but only focuses on the neighboring agent. As such, the red predicted trajectory occur collision. In contrast, our model can provide a more appropriate attention weights distribution that allows the predicted agent to notice important regions and predict a movement to avoid the collision.
In the second scenario, figure (c) visualizes the attention weights of the Social Enforcement module, and figure (d) shows the prediction trajectories. S-WAYS fails to emphasize on the neighboring road-agents with the same walking direction next to the predicted agent; instead, it focuses on the neighboring agent behind. In contrast, our model can provide well-balanced weights on the neighboring agents which help predict more socially plausible trajectories compared to the other.</font>
    <h1>More Results of Waymo Dataset</h1>
      <figure><img src="https://raw.githubusercontent.com/Ego2Eco/Ego2Eco.github.io/master/images/predict_3654.png" width="640" height="480"/></figure>
      <figure><img src="https://raw.githubusercontent.com/Ego2Eco/Ego2Eco.github.io/master/images/predict_3624.png" width="640" height="480"/></figure>
      <figure><img src="https://raw.githubusercontent.com/Ego2Eco/Ego2Eco.github.io/master/images/predict_2820.png" width="640" height="480"/></figure>
      <figure><img src="https://raw.githubusercontent.com/Ego2Eco/Ego2Eco.github.io/master/images/predict_2475.png" width="640" height="480"/></figure>
     <h1>More Results of SDD</h1>
      <figure><img src="https://raw.githubusercontent.com/Ego2Eco/Ego2Eco.github.io/master/images/deathCircle0.png" width="480" height="640"/></figure>
      <figure><img src="https://raw.githubusercontent.com/Ego2Eco/Ego2Eco.github.io/master/images/gate3.png" width="480" height="640" /></figure>
      <figure><img src="https://raw.githubusercontent.com/Ego2Eco/Ego2Eco.github.io/master/images/hyang1.png" width="480" height="640"/></figure>
    </center>

  </body>
  
</html>
